{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "# import shapefile\n",
    "# from shapely.geometry import Polygon\n",
    "# from descartes.patch import PolygonPatch\n",
    "from data_utils import filter_outliers\n",
    "from data_utils import create_ST_map\n",
    "from data_utils import _data_loader\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'D:\\Projects\\MobilityForecast\\Repo\\mobilityforecast\\data')\n",
    "\n",
    "# For Yuri's computer:\n",
    "# os.chdir('..')\n",
    "# os.chdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(r'D:\\Projects\\MobilityForecast\\Repo\\mobilityforecast\\data')\n",
    "\n",
    "# For Yuri's computer:\n",
    "os.chdir('..')\n",
    "os.chdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the data -> Sort by time -> filter out the data (irrleavant) -> ST feature map -> \n",
    "## ST map should capture the demand b/w pick up zone and drop off zone as a function of time(hourly)\n",
    "\n",
    "## The idea is for the Variantional Auto encoder to predict the t+1 ST map given 1,2,3..,t-1,t ST map\n",
    "\n",
    "## The processing of the citi bike and the weather data should also follow the same format.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The ST map should be a 3D tensor of size (n_pickup_zones, n_dropoff_zones, n_time_steps)\n",
    "st_map = create_ST_map(data_path='yellow_tripdata_2022-01.parquet', data_type='Taxi', year=2022, month=1, plotting='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = _data_loader(st_map, val_size=0.15, test_size=0.15)\n",
    "\n",
    "print(train.shape, val.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('yellow_tripdata_2022-01.parquet',engine='pyarrow')\n",
    "# sorting the values is important to capture the temporal relation of the Spatio temporal data\n",
    "df = df.sort_values(by='tpep_pickup_datetime', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tpep_pickup_datetime']=pd.to_datetime(df['tpep_pickup_datetime']) # converting the date-time to python date-time objects to access built-in methods\n",
    "df['tpep_dropoff_datetime']=pd.to_datetime(df['tpep_dropoff_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['store_and_fwd_flag', 'VendorID' , 'RatecodeID', 'payment_type','fare_amount', 'extra' , 'mta_tax', 'tip_amount',\n",
    "'tolls_amount', 'improvement_surcharge','total_amount', 'congestion_surcharge', 'airport_fee', 'trip_distance', 'passenger_count']) # dropping the store and forward flag, VendorID is the company that provided the record(this does not add any value to our study)\n",
    "df = df.dropna(axis=0) # RatecodeID and payment_type are categorical features affecting the price of the trip, we discard this for the moment as this does not add value to our study. \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the date-time objects to date and time\n",
    "\n",
    "df['pickup_year'] = df['tpep_pickup_datetime'].apply(lambda t: t.year)\n",
    "df['pickup_month'] = df['tpep_pickup_datetime'].apply(lambda t: t.month)\n",
    "df['pickup_weekday'] = df['tpep_pickup_datetime'].apply(lambda t: t.day)\n",
    "df['pickup_hour'] = df['tpep_pickup_datetime'].apply(lambda t: t.hour)\n",
    "\n",
    "df = df.drop(columns=['tpep_pickup_datetime', 'tpep_dropoff_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the dates which are irrelavnt to the study\n",
    "\n",
    "df = df[(df.pickup_year == 2022)]\n",
    "df = df[(df.pickup_month == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(columns=['dropoff_year', 'dropoff_month','dropoff_weekday','dropoff_hour', 'pickup_year', 'pickup_month'])\n",
    "df = df.drop(columns=['pickup_year', 'pickup_month'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.pivot_table(columns=[\"PULocationID\", \"DOLocationID\",\"pickup_weekday\", \"pickup_hour\"], aggfunc='size').reset_index(name='demand')\n",
    "features = pd.DataFrame(features).reset_index(drop=True)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 265+1\n",
    "cols = 265+1\n",
    "\n",
    "days = np.unique(features.pickup_weekday)\n",
    "hours = np.unique(features.pickup_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_days = []\n",
    "features_hours = []\n",
    "features_days = [features[features.pickup_weekday == i] for i in days]\n",
    "for i in range(0,len(features_days)):\n",
    "    for j in hours:\n",
    "        features_hours.append(features_days[i][features_days[i].pickup_hour == j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ST_map = np.zeros((rows,cols, len(features_hours)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(features_hours)):\n",
    "    features_hours[i] = features_hours[i].drop(columns=[\"pickup_weekday\",\"pickup_hour\"])\n",
    "    rind = np.array(features_hours[i].PULocationID.array)\n",
    "    cind = np.array(features_hours[i].DOLocationID.array)\n",
    "    demand = np.array(features_hours[i].demand.array)\n",
    "    ST_map[rind,cind,i] = demand\n",
    "ST_map = ST_map[1::,1::,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12,12))\n",
    "sns.heatmap(ST_map[:,:,0], ax=ax1)\n",
    "sns.heatmap(ST_map[:,:,17], ax=ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('202201-citibike-tripdata.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-18 08:23:52</td>\n",
       "      <td>2022-01-18 08:28:18</td>\n",
       "      <td>40.688489</td>\n",
       "      <td>-73.991160</td>\n",
       "      <td>40.692395</td>\n",
       "      <td>-73.993379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-21 09:03:22</td>\n",
       "      <td>2022-01-21 09:05:44</td>\n",
       "      <td>40.727243</td>\n",
       "      <td>-73.976831</td>\n",
       "      <td>40.727408</td>\n",
       "      <td>-73.981420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-22 14:28:32</td>\n",
       "      <td>2022-01-22 14:53:18</td>\n",
       "      <td>40.741740</td>\n",
       "      <td>-73.994156</td>\n",
       "      <td>40.762009</td>\n",
       "      <td>-73.996975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-19 14:49:47</td>\n",
       "      <td>2022-01-19 14:54:02</td>\n",
       "      <td>40.764175</td>\n",
       "      <td>-73.915840</td>\n",
       "      <td>40.768692</td>\n",
       "      <td>-73.924957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-16 14:36:06</td>\n",
       "      <td>2022-01-16 14:44:06</td>\n",
       "      <td>40.685376</td>\n",
       "      <td>-73.983021</td>\n",
       "      <td>40.696233</td>\n",
       "      <td>-73.991421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-01-28 23:20:01</td>\n",
       "      <td>2022-01-28 23:32:18</td>\n",
       "      <td>40.760301</td>\n",
       "      <td>-73.998842</td>\n",
       "      <td>40.752062</td>\n",
       "      <td>-73.981632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-01-28 17:12:46</td>\n",
       "      <td>2022-01-28 17:27:03</td>\n",
       "      <td>40.690725</td>\n",
       "      <td>-73.951335</td>\n",
       "      <td>40.671649</td>\n",
       "      <td>-73.963115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-01-04 22:12:48</td>\n",
       "      <td>2022-01-04 22:18:27</td>\n",
       "      <td>40.741740</td>\n",
       "      <td>-73.994156</td>\n",
       "      <td>40.735877</td>\n",
       "      <td>-73.982050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-01-08 11:34:22</td>\n",
       "      <td>2022-01-08 11:43:14</td>\n",
       "      <td>40.730386</td>\n",
       "      <td>-74.002150</td>\n",
       "      <td>40.719105</td>\n",
       "      <td>-73.999733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-01-26 19:04:18</td>\n",
       "      <td>2022-01-26 19:09:05</td>\n",
       "      <td>40.741740</td>\n",
       "      <td>-73.994156</td>\n",
       "      <td>40.749156</td>\n",
       "      <td>-73.991600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            started_at             ended_at  start_lat  start_lng    end_lat  \\\n",
       "0  2022-01-18 08:23:52  2022-01-18 08:28:18  40.688489 -73.991160  40.692395   \n",
       "1  2022-01-21 09:03:22  2022-01-21 09:05:44  40.727243 -73.976831  40.727408   \n",
       "2  2022-01-22 14:28:32  2022-01-22 14:53:18  40.741740 -73.994156  40.762009   \n",
       "3  2022-01-19 14:49:47  2022-01-19 14:54:02  40.764175 -73.915840  40.768692   \n",
       "4  2022-01-16 14:36:06  2022-01-16 14:44:06  40.685376 -73.983021  40.696233   \n",
       "5  2022-01-28 23:20:01  2022-01-28 23:32:18  40.760301 -73.998842  40.752062   \n",
       "6  2022-01-28 17:12:46  2022-01-28 17:27:03  40.690725 -73.951335  40.671649   \n",
       "7  2022-01-04 22:12:48  2022-01-04 22:18:27  40.741740 -73.994156  40.735877   \n",
       "8  2022-01-08 11:34:22  2022-01-08 11:43:14  40.730386 -74.002150  40.719105   \n",
       "9  2022-01-26 19:04:18  2022-01-26 19:09:05  40.741740 -73.994156  40.749156   \n",
       "\n",
       "     end_lng  \n",
       "0 -73.993379  \n",
       "1 -73.981420  \n",
       "2 -73.996975  \n",
       "3 -73.924957  \n",
       "4 -73.991421  \n",
       "5 -73.981632  \n",
       "6 -73.963115  \n",
       "7 -73.982050  \n",
       "8 -73.999733  \n",
       "9 -73.991600  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['ride_id', 'rideable_type', 'start_station_name', 'start_station_id', 'end_station_name', 'end_station_id', 'member_casual'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(r'D:\\Projects\\MobilityForecast\\Repo\\mobilityforecast\\help\\images')\n",
    "# img1 = plt.imread('nyc_-74.3_-73.7_40.5_40.9.png')\n",
    "# img2 = plt.imread('nyc_-74.5_-72.8_40.5_41.8.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_grid(lat, lon, num_clusters):\n",
    "    x = np.array([lat, lon]).T\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
    "    label = kmeans.fit_predict(x)\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    u_labels = np.unique(label)\n",
    "    for i in u_labels:\n",
    "        plt.scatter(x[label == i , 0] , x[label == i , 1] , label = i)\n",
    "    plt.scatter(centroids[:,0] , centroids[:,1] , s = 15, color = 'k')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_grid(df.start_lat, df.start_lng, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = 4\n",
    "\n",
    "start_lat_min, start_lat_max = df.start_lat.agg(['min','max'])\n",
    "start_lng_min, start_lng_max = df.start_lng.agg(['min','max'])\n",
    "\n",
    "end_lat_min, end_lat_max = df.end_lat.agg(['min','max'])\n",
    "end_lng_min, end_lng_max = df.end_lng.agg(['min','max'])\n",
    "\n",
    "west = min(start_lat_min, end_lat_min)\n",
    "east = max(start_lat_max, end_lat_max)\n",
    "\n",
    "south = min(start_lng_min, end_lng_min)\n",
    "north = max(start_lng_max, end_lng_max)\n",
    "\n",
    "lat_bins = np.linspace(west,east,regions)\n",
    "lng_bins = np.linspace(south, north, regions)\n",
    "\n",
    "#bins = np.stack(np.meshgrid(lat_bins, lng_bins)).T.reshape(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(map(int, range(regions)))\n",
    "\n",
    "cord_bins = np.array(np.meshgrid(np.arange(regions), np.arange(regions))).T.reshape(-1,2)\n",
    "cord_bins = list(map(tuple, cord_bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['start_lat_regions']=pd.cut(df['start_lat'], bins=regions,labels = names, retbins=False, right=True, include_lowest=True)\n",
    "df['start_lng_regions']=pd.cut(df['start_lng'], bins=regions,labels= names, retbins=False, right=True, include_lowest=True)\n",
    "\n",
    "df['end_lat_regions']=pd.cut(df['end_lat'], bins=regions,labels = names, retbins=False, right=True, include_lowest=True)\n",
    "df['end_lng_regions']=pd.cut(df['end_lng'], bins=regions,labels= names, retbins=False, right=True, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp = np.array([*list(zip(df.lat_regions, df.lng_regions))])\n",
    "df['PU_region'] =list(zip(df.start_lat_regions, df.start_lng_regions)) #np.array([*tmp]).tolist()\n",
    "df['DO_region'] =list(zip(df.end_lat_regions, df.end_lng_regions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>PU_region</th>\n",
       "      <th>DO_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-18 08:23:52</td>\n",
       "      <td>2022-01-18 08:28:18</td>\n",
       "      <td>40.688489</td>\n",
       "      <td>-73.991160</td>\n",
       "      <td>40.692395</td>\n",
       "      <td>-73.993379</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-21 09:03:22</td>\n",
       "      <td>2022-01-21 09:05:44</td>\n",
       "      <td>40.727243</td>\n",
       "      <td>-73.976831</td>\n",
       "      <td>40.727408</td>\n",
       "      <td>-73.981420</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-22 14:28:32</td>\n",
       "      <td>2022-01-22 14:53:18</td>\n",
       "      <td>40.741740</td>\n",
       "      <td>-73.994156</td>\n",
       "      <td>40.762009</td>\n",
       "      <td>-73.996975</td>\n",
       "      <td>(1, 0)</td>\n",
       "      <td>(2, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-19 14:49:47</td>\n",
       "      <td>2022-01-19 14:54:02</td>\n",
       "      <td>40.764175</td>\n",
       "      <td>-73.915840</td>\n",
       "      <td>40.768692</td>\n",
       "      <td>-73.924957</td>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-16 14:36:06</td>\n",
       "      <td>2022-01-16 14:44:06</td>\n",
       "      <td>40.685376</td>\n",
       "      <td>-73.983021</td>\n",
       "      <td>40.696233</td>\n",
       "      <td>-73.991421</td>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            started_at             ended_at  start_lat  start_lng    end_lat  \\\n",
       "0  2022-01-18 08:23:52  2022-01-18 08:28:18  40.688489 -73.991160  40.692395   \n",
       "1  2022-01-21 09:03:22  2022-01-21 09:05:44  40.727243 -73.976831  40.727408   \n",
       "2  2022-01-22 14:28:32  2022-01-22 14:53:18  40.741740 -73.994156  40.762009   \n",
       "3  2022-01-19 14:49:47  2022-01-19 14:54:02  40.764175 -73.915840  40.768692   \n",
       "4  2022-01-16 14:36:06  2022-01-16 14:44:06  40.685376 -73.983021  40.696233   \n",
       "\n",
       "     end_lng PU_region DO_region  \n",
       "0 -73.993379    (0, 0)    (0, 1)  \n",
       "1 -73.981420    (1, 1)    (1, 1)  \n",
       "2 -73.996975    (1, 0)    (2, 1)  \n",
       "3 -73.924957    (2, 3)    (2, 2)  \n",
       "4 -73.991421    (0, 1)    (1, 1)  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['start_lat_regions','start_lng_regions','end_lat_regions','end_lng_regions'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(cord_bins)):\n",
    "    df.loc[df['PU_region'] == cord_bins[i], 'PU_region'] = i+1\n",
    "    df.loc[df['DO_region'] == cord_bins[i], 'DO_region'] = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>PU_region</th>\n",
       "      <th>DO_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-18 08:23:52</td>\n",
       "      <td>2022-01-18 08:28:18</td>\n",
       "      <td>40.688489</td>\n",
       "      <td>-73.991160</td>\n",
       "      <td>40.692395</td>\n",
       "      <td>-73.993379</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-21 09:03:22</td>\n",
       "      <td>2022-01-21 09:05:44</td>\n",
       "      <td>40.727243</td>\n",
       "      <td>-73.976831</td>\n",
       "      <td>40.727408</td>\n",
       "      <td>-73.981420</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-22 14:28:32</td>\n",
       "      <td>2022-01-22 14:53:18</td>\n",
       "      <td>40.741740</td>\n",
       "      <td>-73.994156</td>\n",
       "      <td>40.762009</td>\n",
       "      <td>-73.996975</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-19 14:49:47</td>\n",
       "      <td>2022-01-19 14:54:02</td>\n",
       "      <td>40.764175</td>\n",
       "      <td>-73.915840</td>\n",
       "      <td>40.768692</td>\n",
       "      <td>-73.924957</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-16 14:36:06</td>\n",
       "      <td>2022-01-16 14:44:06</td>\n",
       "      <td>40.685376</td>\n",
       "      <td>-73.983021</td>\n",
       "      <td>40.696233</td>\n",
       "      <td>-73.991421</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            started_at             ended_at  start_lat  start_lng    end_lat  \\\n",
       "0  2022-01-18 08:23:52  2022-01-18 08:28:18  40.688489 -73.991160  40.692395   \n",
       "1  2022-01-21 09:03:22  2022-01-21 09:05:44  40.727243 -73.976831  40.727408   \n",
       "2  2022-01-22 14:28:32  2022-01-22 14:53:18  40.741740 -73.994156  40.762009   \n",
       "3  2022-01-19 14:49:47  2022-01-19 14:54:02  40.764175 -73.915840  40.768692   \n",
       "4  2022-01-16 14:36:06  2022-01-16 14:44:06  40.685376 -73.983021  40.696233   \n",
       "\n",
       "     end_lng PU_region DO_region  \n",
       "0 -73.993379         1         2  \n",
       "1 -73.981420         6         6  \n",
       "2 -73.996975         5        10  \n",
       "3 -73.924957        12        11  \n",
       "4 -73.991421         2         6  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('mobilityforecast')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a489ebabc6b1c3c996df92d9378f45c983839505199bbf18af484bb22de14d32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
