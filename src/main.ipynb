{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import PIL\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "# import tensorflow.contrib as tf_contrib\n",
    "import time\n",
    "\n",
    "#imp\n",
    "tf.keras.backend.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### A simplified attention block\n",
    "def hw_flatten(x) :\n",
    "    # return tf.reshape(x, shape=[x.shape[0], -1, x.shape[-1]])\n",
    "    return tf.reshape(x, shape=(x.shape[0], -1, x.shape[-1]))\n",
    "\n",
    "def attention(x, channels=265):\n",
    "\n",
    "    f = tf.keras.layers.Conv2D(filters=1, kernel_size=1, strides=1, padding='same', use_bias=True)(x) # [bs, h, w, c']\n",
    "    g = tf.keras.layers.Conv2D(filters=1, kernel_size=1, strides=1, padding='same', use_bias=True)(x) # [bs, h, w, c']\n",
    "    h = tf.keras.layers.Conv2D(filters=1, kernel_size=1, strides=1, padding='same', use_bias=True)(x) # [bs, h, w, c]\n",
    "    # print('h', h.shape)\n",
    "    # N = h * w\n",
    "    # s = tf.linalg.matmul(hw_flatten(g), hw_flatten(f), transpose_b=True) # # [bs, N, N]\n",
    "    s = tf.matmul(g, f, transpose_b=True) # # [bs, N, N]\n",
    "    # s = tf.matmul(tf.keras.layers.Flatten()(g), tf.keras.layers.Flatten()(f), transpose_b=True) # # [bs, N, N]\n",
    "    # print('s', s.shape)\n",
    "    beta = tf.nn.softmax(s)  # attention map\n",
    "    # print('beta', beta.shape)\n",
    "\n",
    "    # o = tf.linalg.matmul(beta, hw_flatten(h)) # [bs, N, C]\n",
    "    o = tf.matmul(beta, h) # [bs, N, C]\n",
    "    # o = tf.linalg.matmul(beta, tf.keras.layers.Flatten()(h)) # [bs, N, C]\n",
    "    # print('o', o.shape)\n",
    "    # Unsure if this is correct, see documentation: https://www.tensorflow.org/api_docs/python/tf/compat/v1/get_variable#migrate-to-tf2\n",
    "    gamma = tf.compat.v1.get_variable(\"gamma\", [1], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "    # o = tf.reshape(o, shape=x.shape) # [bs, h, w, C]\n",
    "    o = tf.keras.layers.Conv2D(filters=channels, kernel_size=1, strides=1, padding='same', use_bias=True)(o)\n",
    "\n",
    "    x = gamma * o + x\n",
    "\n",
    "    return x\n",
    "\n",
    "class Sampling(tf.keras.layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon # this formula is considered best practice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv3D_Block(inp_shape):\n",
    "        inp = tf.keras.layers.Input(shape=inp_shape)\n",
    "\n",
    "        # We will construct 4 `ConvLSTM2D` layers with batch normalization,\n",
    "        # followed by a `Conv3D` layer for the spatiotemporal outputs.\n",
    "        x = tf.keras.layers.ConvLSTM2D(filters=4, kernel_size=(3), strides=(2,2), padding=\"same\", return_sequences=True, activation=\"relu\", data_format='channels_last', )(inp)\n",
    "        #x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.ConvLSTM2D(filters=8, kernel_size=(3), strides=(2,2), padding=\"same\", return_sequences=True, activation=\"relu\")(inp)\n",
    "        #x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.ConvLSTM2D(filters=16, kernel_size=(3), strides=(2,2), padding=\"same\", return_sequences=True, activation=\"relu\")(x)\n",
    "        #x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.ConvLSTM2D(filters=32, kernel_size=(3), strides=(2,2), padding=\"same\", return_sequences=True, activation=\"relu\")(x)\n",
    "        #x = tf.keras.layers.BatchNormalization()(x)\n",
    "        res1 = tf.keras.layers.Conv3D(filters=1, kernel_size=(1,1,1), padding=\"same\")(x)\n",
    "        res1 = tf.keras.layers.LeakyReLU(alpha=0.05)(res1)\n",
    "        res1 = tf.keras.layers.MaxPooling3D(pool_size=2, )(res1)\n",
    "        #res1 = tf.keras.layers.BatchNormalization()(res1)\n",
    "        # attention\n",
    "        x = attention(res1, channels=265)\n",
    "        # residual\n",
    "        x = tf.keras.layers.Add()([res1, x])\n",
    "        x = tf.keras.layers.Dense(16,activation='relu')(x)\n",
    "        x = tf.keras.layers.Dense(32,activation='relu')(x)\n",
    "        x = tf.keras.layers.Dense(64,activation='relu')(x)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha=0.05)(x)\n",
    "\n",
    "        # Next, we will build the complete model and compile it.\n",
    "        model = tf.keras.Model(inputs=inp, outputs=x)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_model(latent_dim, inp_shape):\n",
    "    \"\"\" Adapted from Laurence Moroney's Coursera course on VAEs: https://www.coursera.org/lecture/generative-deep-learning-with-tensorflow/sampling-layer-and-encoder-G2mJr\"\"\"\n",
    "    demand_model = Conv3D_Block(inp_shape[0])\n",
    "    ex_f_model = Conv3D_Block(inp_shape[1])\n",
    "    combined = tf.keras.layers.concatenate([demand_model.output, ex_f_model.output], axis=-1)\n",
    "    x = tf.keras.layers.Dense(16, activation='relu')(combined)\n",
    "    x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    z_mean = tf.keras.layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "    z_log_var = tf.keras.layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "    encoder = tf.keras.Model(inputs=[demand_model.input, ex_f_model.input], outputs=[z_mean, z_log_var, z], name=\"encoder\")\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model(latent_dim):\n",
    "    \n",
    "    latent_inputs = tf.keras.Input(shape=(latent_dim,))\n",
    "    x = tf.keras.layers.Dense(34*34*32, activation='relu')(latent_inputs)\n",
    "    x = tf.keras.layers.Reshape(target_shape=(34,34,32))(x)\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=(3), strides=2, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters=16, kernel_size=(3), strides=2, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters=8, kernel_size=(3), strides=2, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Conv2D(filters=1, kernel_size=1, strides=1)(x)\n",
    "    x = tf.keras.layers.Reshape(target_shape=(1,272,272,1))(x)\n",
    "    x = tf.keras.layers.Conv3DTranspose(filters=1, kernel_size=(3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.05)(x)\n",
    "\n",
    "    #generator = tf.keras.Model(latent_inputs, outputs=[x_real, x_enc, x_fake], name=\"generator\")\n",
    "    generator = tf.keras.Model(latent_inputs, outputs=x, name=\"generator\")\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(tf.keras.Model):\n",
    "    def __init__(self, encoder, generator, **kwargs):\n",
    "        super(CVAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.generator = generator\n",
    "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return[self.total_loss_tracker, self.reconstruction_loss_tracker, self.kl_loss_tracker]\n",
    "\n",
    "    def train_step(self,data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_variance, z = self.encoder([data[0], data[1]])\n",
    "            reconstruction = self.generator(z)\n",
    "            reconstruction_loss = tf.reduce_mean(tf.reduce_sum(tf.keras.losses.binary_crossentropy(data[0], reconstruction), axis=(1,2)))\n",
    "            kl_loss = -0.5 * (1 + z_log_variance - tf.square(z_mean) - tf.exp(z_log_variance))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss =reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "\n",
    "        return { \n",
    "            \"loss\":self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, it's common practice to avoid using batch normalization when training VAEs, since the additional stochasticity due to using mini-batches may aggravate instability on top of the stochasticity from sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 4\n",
    "batch_size = 1 # Paper: 32\n",
    "channel = 1\n",
    "height = 272\n",
    "width = 272\n",
    "depth = 6\n",
    "inp_shape = [(depth, height, width, channel), (depth, height, width, channel)]\n",
    "encoder = encoder_model(latent_dim, inp_shape)\n",
    "generator = generator_model(latent_dim)\n",
    "vae = CVAE(encoder, generator)\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.random.normal(shape = (batch_size, depth, height, width, channel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mean, z_log_variance, z = encoder([train_data, train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.stack([train_data, train_data], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 10s 10s/step - loss: -40.0968 - reconstruction_loss: -40.0968 - kl_loss: 1.4901e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2989183bc08>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(data, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('mobilityforecast')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a489ebabc6b1c3c996df92d9378f45c983839505199bbf18af484bb22de14d32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
